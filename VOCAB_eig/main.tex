\documentclass{ximera}
\input{../preamble.tex}

\title{Essential Vocabulary} \license{CC BY-NC-SA 4.0}



\begin{document}
\begin{abstract}
\end{abstract}
\maketitle


\begin{onlineOnly}
\section*{Essential Vocabulary}
Here is a  \href{https://quizlet.com/906040972/chapter-8-vocabulary-flash-cards/?i=y06sd&x=1jqt}{link to a list of these terms on Quizlet}
\end{onlineOnly}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Algebraic multiplicity of an eigenvalue
\begin{expandable}{}{}
    The multiplicity of an eigenvalue as a root of the characteristic equation.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Characteristic equation
\begin{expandable}{}{}
    The equation 
$$\mbox{det}(A-\lambda I) = 0$$ is called the \dfn{characteristic equation} of $A$. 
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Characteristic polynomial
\begin{expandable}{}{}
    The polynomial 
$$\mbox{det}(A-\lambda I)$$ is called the \dfn{characteristic polynomial} of $A$. 
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Diagonalizable matrix
\begin{expandable}{}{}
    Let $A$ be an $n\times n$ matrix. Then $A$ is said to be \dfn{diagonalizable} if there exists an invertible matrix $P$ such that
\begin{equation*}
P^{-1}AP=D
\end{equation*}
where $D$ is a diagonal matrix.  In other words, a matrix $A$ is diagonalizable if it is similar to a diagonal matrix, $A \sim D$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Eigenspace
\begin{expandable}{}{}
    If $\lambda$ is an eigenvalue of an $n \times n$ matrix, the set of all eigenvectors associated to $\lambda$ along with the zero vector is the \dfn{eigenspace} associated to $\lambda$.  The eigenspace is a subspace of $\RR^n$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Eigenvalue
\begin{expandable}{}{}
    Let $A$ be an $n \times n$ matrix.  We say that a scalar $\lambda$ is an \dfn{eigenvalue} of $A$ if $$A\vec{x} = \lambda \vec{x}$$
for some nonzero vector $x$.
We say that $x$ is an \dfn{eigenvector} of $A$ associated with the eigenvalue $\lambda$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Eigenvalue decomposition
\begin{expandable}{}{}
    If $\lambda$ is an eigenvalue of an $n \times n$ matrix, the set of all eigenvectors associated to $\lambda$ along with the zero vector is the \dfn{eigenspace} associated to $\lambda$.  The eigenspace is a subspace of $\RR^n$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Eigenvector
\begin{expandable}{}{}
    Let $A$ be an $n \times n$ matrix.  We say that a non-zero vector $\vec{x}$ is an \dfn{eigenvector} of $A$ if $$A\vec{x} = \lambda \vec{x}$$
for some scalar $\lambda$.
We say that $\lambda$ is an \dfn{eigenvalue} of $A$ associated with the eigenvector $\vec{x}$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Geometric multiplicity of an eigenvalue
\begin{expandable}{}{}
    The \dfn{geometric multiplicity} of an eigenvalue $\lambda$ is the dimension of the corresponding eigenspace $\mathcal{S}_\lambda$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Gershgorin disk
\begin{expandable}{}{}
    A circle in the complex plane which has a diagonal entry of a matrix as its center and the sum of the absolute values of the other entries in that row (or column) as its radius.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Gershgorin's Theorem
\begin{expandable}{}{}
    \dfn{Gershgorinâ€™s theorem} says that the $n$ eigenvalues of an $n \times n$ matrix can be found in the region in the complex plane consisting of the $n$ Gershgorin disks.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Power method (and its variants)
\begin{expandable}{}{}
    The \dfn{power method} is an iterative method for computing the dominant eigenvalue of a matrix. It variants can compute the smallest eigenvalue or the eigenvalue closest to some target.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Properties of similar matrices
\begin{expandable}{}{}
Similar matrices must have the same...
\begin{enumerate}
    \item determinant,

    \item rank,

    \item trace,

    \item characteristic polynomial, 

    and

    \item eigenvalues.

\end{enumerate}
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

Similar matrices
\begin{expandable}{}{}
    If $A$ and $B$ are $n \times n$ matrices, we say that $A$ and $B$ are \dfn{similar}, if $B = P^{-1}AP$ for some invertible matrix $P$.  In this case we write $A \sim B$.
\end{expandable}

\begin{tikzpicture}[scale=1]
   \filldraw[teal, opacity=0.3](0,0)--(20,0)--(20,0.1)--(0,0.1)--cycle;
 \end{tikzpicture}

 
\end{document}


